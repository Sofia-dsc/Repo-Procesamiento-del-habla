{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGEWEBx2hAGIPHyBvVQ6qY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sofia-dsc/Repo-Procesamiento-del-habla/blob/main/Datasets_Sof%C3%ADa_Rold%C3%A1n.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Actividades\n",
        "\n",
        "1. Vectorizar documentos. Tomar 5 documentos al azar y medir similaridad con el resto de los documentos. Estudiar los 5 documentos más similares de cada uno analizar si tiene sentido la similaridad según el contenido del texto y la etiqueta de clasificación.\n",
        "\n",
        "2. Entrenar modelos de clasificación Naïve Bayes para maximizar el desempeño de clasificación (f1-score macro) en el conjunto de datos de test. Considerar cambiar parámteros de instanciación del vectorizador y los modelos y probar modelos de Naïve Bayes Multinomial y ComplementNB.\n",
        "\n",
        "3. Transponer la matriz documento-término. De esa manera se obtiene una matriz término-documento que puede ser interpretada como una colección de vectorización de palabras. Estudiar ahora similaridad entre palabras tomando 5 palabras y estudiando sus 5 más similares. La elección de palabras no debe ser al azar para evitar la aparición de términos poco interpretables, elegirlas \"manualmente\".\n",
        "\n"
      ],
      "metadata": {
        "id": "nE4OOhANvSxc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vectorización de texto y modelo de clasificación Naïve Bayes con el dataset 20 newsgroups"
      ],
      "metadata": {
        "id": "S9W9XRAXvbga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importo las librerías que voy a necesitar\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "Uvz8QqYgvt4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importo el dataset\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "hYPLqtdhwZGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separo y cargo los datos en train y test\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"
      ],
      "metadata": {
        "id": "QFYHq5AFwjEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comienzo el vectorizador y accedo al texto\n",
        "tfidfvect = TfidfVectorizer()\n",
        "newsgroups_train.data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "Gye9T1bgxX0I",
        "outputId": "1d9a13fc-15b3-416d-c8a2-0ded47e82e1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtengo el vocabulario y calculo el vector tf-idf\n",
        "X_train = tfidfvect.fit_transform(newsgroups_train.data)"
      ],
      "metadata": {
        "id": "wKoJKDmUzCvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(X_train))\n",
        "print(f'shape: {X_train.shape}')\n",
        "print(f'cantidad de documentos: {X_train.shape[0]}')\n",
        "print(f'tamaño del vocabulario (dimensionalidad de los vectores): {X_train.shape[1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFrFwVYuzecg",
        "outputId": "e3ced1ff-9532-4b5b-d8d1-a46accb22f03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse._csr.csr_matrix'>\n",
            "shape: (11314, 101631)\n",
            "cantidad de documentos: 11314\n",
            "tamaño del vocabulario (dimensionalidad de los vectores): 101631\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# En y_train guardo los targets que son enteros\n",
        "y_train = newsgroups_train.target\n",
        "y_train[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ii0LiS_7zzNQ",
        "outputId": "1e7ad80e-1383-47db-93c7-ca9d68e1b6d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tomo 5 documentos al azar con random\n",
        "import random"
      ],
      "metadata": {
        "id": "BovDhoZi0CtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(1819)"
      ],
      "metadata": {
        "id": "NpWqgim60ziF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_azar = random.sample(newsgroups_train.data, 5)"
      ],
      "metadata": {
        "id": "KZObiDvS08TM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Veo que documentos he seleccionado\n",
        "for i, doc in enumerate(docs_azar):\n",
        "    print(f\"Documento {i + 1}:\\n{doc}\\n{'-' * 80}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPGm7bf_1FQh",
        "outputId": "79361834-5a38-4faa-8726-d8cd5415d5eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documento 1:\n",
            "The floppy is served by DMA on the motherboard,\n",
            "and original DMA-controller can't reach more than the first\n",
            "16MB (The address-space of the ISA-bus)\n",
            "joerg\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Documento 2:\n",
            "I have a Tseng labs video card that gives me problems when I do anything in \n",
            "super VGA mode.  CHECKIT v3.0 reports a Video Page Frame Address Error at \n",
            "Page Frame #7.  What does this mean and how (if I can) could this be fixed?\n",
            "The card Says ET4000Ax on it.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Documento 3:\n",
            "\n",
            "I use the ashtray to keep change and other items in. I converted the \n",
            "cigarette lighter into a volume control knob for my in trunk subwoofer!\n",
            "\n",
            "\n",
            "\n",
            "                                                  .  \n",
            "                                                 /                \n",
            "Larry                            __/    _______/_                 \n",
            "keys@csmes.ncsl.nist.gov       /                  \\               \n",
            "                          _____     __     _____    \\------- ===\n",
            "            ----------- / ____/   /  /   /__  __/              \\\n",
            "         /     ___    /  / ___   /  /      / /    ____          |\n",
            "        |    /      \\/ /__ /  | /  /__  __/ /__ /       \\      / \n",
            "        /___         \\_______/ /_____/ /______/            ====OO\n",
            "            \\       /                           \\       /         \n",
            "                -            1990 2.0 16v           -\n",
            "\n",
            "\n",
            "       ---------------- FAHRVERGNUGEN FOREVER! --------------------            \n",
            "            The fact that I need to explain it to you indicates\n",
            "            that you probably wouldn't understand anyway!\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Documento 4:\n",
            "For whoever does the will of my Father in heaven is my brother and sister\n",
            "and mother.\" \n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Documento 5:\n",
            "\n",
            "I pondered it for all of ten seconds when I realised that since\n",
            "we don't have any reliable statistics for sexual promiscuity,\n",
            "and since the whole issue of \"depression\" isn't at all well \n",
            "defined for earlier centuries, you are probably talking crap.\n",
            "\n",
            "Of course, you could pull a Mozumder on us, and say that people\n",
            "who are having sex outside marriage are *defined* to be depressed.\n",
            "\n",
            "I can't say I'd ever noticed, myself.\n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Mido la similaridad de los docs seleccionados y el resto de documentos\n",
        "for i, doc in enumerate(docs_azar):\n",
        "    vector = tfidfvect.transform([doc])\n",
        "    coseno = cosine_similarity(vector, X_train)[0]\n",
        "    mostsim = np.argsort(coseno)[::-1][1:6]\n",
        "    print(f'Documento {i} de la clase: {newsgroups_train.target_names[y_train[newsgroups_train.data.index(doc)]]}')\n",
        "\n",
        "#Visualizo los 5 documentos más similares\n",
        "    print(f'Los 5 documentos más similares son:')\n",
        "    for idx in mostsim:\n",
        "        print(f'Clase: {newsgroups_train.target_names[y_train[idx]]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0D6HNwc29__",
        "outputId": "227d09a6-3bfd-4d0c-be2b-f315145f94c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documento 0 de la clase: comp.sys.ibm.pc.hardware\n",
            "Los 5 documentos más similares son:\n",
            "Clase: comp.sys.ibm.pc.hardware\n",
            "Clase: comp.sys.ibm.pc.hardware\n",
            "Clase: comp.sys.ibm.pc.hardware\n",
            "Clase: comp.sys.ibm.pc.hardware\n",
            "Clase: comp.sys.ibm.pc.hardware\n",
            "Documento 1 de la clase: comp.sys.ibm.pc.hardware\n",
            "Los 5 documentos más similares son:\n",
            "Clase: comp.sys.mac.hardware\n",
            "Clase: comp.graphics\n",
            "Clase: comp.sys.mac.hardware\n",
            "Clase: comp.sys.ibm.pc.hardware\n",
            "Clase: comp.graphics\n",
            "Documento 2 de la clase: rec.autos\n",
            "Los 5 documentos más similares son:\n",
            "Clase: rec.autos\n",
            "Clase: rec.autos\n",
            "Clase: rec.autos\n",
            "Clase: rec.autos\n",
            "Clase: comp.windows.x\n",
            "Documento 3 de la clase: soc.religion.christian\n",
            "Los 5 documentos más similares son:\n",
            "Clase: soc.religion.christian\n",
            "Clase: soc.religion.christian\n",
            "Clase: soc.religion.christian\n",
            "Clase: talk.religion.misc\n",
            "Clase: soc.religion.christian\n",
            "Documento 4 de la clase: alt.atheism\n",
            "Los 5 documentos más similares son:\n",
            "Clase: alt.atheism\n",
            "Clase: talk.politics.misc\n",
            "Clase: alt.atheism\n",
            "Clase: talk.religion.misc\n",
            "Clase: rec.sport.baseball\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Entreno los modelos\n",
        "\n",
        "# Modelo Naive Bayes Multinomial\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "X_test = tfidfvect.transform(newsgroups_test.data)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(f'F1-score (macro): {f1_score(newsgroups_test.target, y_pred, average=\"macro\")}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggVBCvhw3zyQ",
        "outputId": "31da7294-6c6a-4cd4-a18f-ecd01ca45e4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score (macro): 0.5854345727938506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo Naive Bayes Complement\n",
        "clf2 = ComplementNB()\n",
        "clf2.fit(X_train, y_train)\n",
        "y_pred2 = clf2.predict(X_test)\n",
        "print(f'F1-score (macro): {f1_score(newsgroups_test.target, y_pred2, average=\"macro\")}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upAPQsG64Mts",
        "outputId": "938b988b-05de-4341-98d1-bfc0f531122a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score (macro): 0.692953349950875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transpongo la matriz documento-término\n",
        "X_train_transposed = X_train.T\n",
        "\n",
        "# Pongo las 5 palabras elegidas para evaluar la similaridad\n",
        "palabras = ['education', 'space', 'graphics', 'business', 'history']\n",
        "\n",
        "for palabra in palabras:\n",
        "    idx = tfidfvect.vocabulary_[palabra]\n",
        "    idx2word = {v: k for k, v in tfidfvect.vocabulary_.items()}\n",
        "    palabra_vect = X_train_transposed[idx]\n",
        "    similar_words = cosine_similarity(palabra_vect, X_train_transposed)[0]\n",
        "    most_similar_idx = np.argsort(similar_words)[::-1][1:6]\n",
        "    print(f'Palabra elegida: {palabra}')\n",
        "    for idx in most_similar_idx:\n",
        "        print(f'Palabra similar encontrada: {idx2word[idx]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k56Qh8Yg45G7",
        "outputId": "374436f7-4823-4016-9837-f6ec571a5ebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabra elegida: education\n",
            "Palabra similar encontrada: abstinence\n",
            "Palabra similar encontrada: pregnancy\n",
            "Palabra similar encontrada: joplin\n",
            "Palabra similar encontrada: janis\n",
            "Palabra similar encontrada: vaunted\n",
            "Palabra elegida: space\n",
            "Palabra similar encontrada: nasa\n",
            "Palabra similar encontrada: seds\n",
            "Palabra similar encontrada: shuttle\n",
            "Palabra similar encontrada: enfant\n",
            "Palabra similar encontrada: seti\n",
            "Palabra elegida: graphics\n",
            "Palabra similar encontrada: comp\n",
            "Palabra similar encontrada: grieggs\n",
            "Palabra similar encontrada: 3d\n",
            "Palabra similar encontrada: cfd\n",
            "Palabra similar encontrada: discused\n",
            "Palabra elegida: business\n",
            "Palabra similar encontrada: uwo\n",
            "Palabra similar encontrada: regina\n",
            "Palabra similar encontrada: s4lawren\n",
            "Palabra similar encontrada: gophers\n",
            "Palabra similar encontrada: reunion\n",
            "Palabra elegida: history\n",
            "Palabra similar encontrada: inalcik\n",
            "Palabra similar encontrada: tibor\n",
            "Palabra similar encontrada: avigdor\n",
            "Palabra similar encontrada: halasi\n",
            "Palabra similar encontrada: kazimir\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Enfoque, aproximación y experiencia.**\n",
        "\n",
        "### Utilicé técnicas de vectorización como TF-IDF para transformar textos en representaciones numéricas que puedan ser analizadas, implementé medidas de similitud, como la similitud del coseno, para entender cómo se relacionan los documentos y las palabras. y apliqué métricas como el F1-score (macro) para evaluar el rendimiento de los modelos de clasificación y realizar ajustes en función de los resultados.\n",
        "\n",
        "### Este trabajo me aportó bastante experiencia nueva porque no conocía este modo de trabajar documentos y buscar similitudes, asique como era nuevo para mi tuve que investigar en internet y basarme en el contenido de las clases."
      ],
      "metadata": {
        "id": "SgTQuean7fo3"
      }
    }
  ]
}